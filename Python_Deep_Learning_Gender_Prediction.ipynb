{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d7bdc0-67f5-4d16-a239-7b27c52d71c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries installed and imported successfully!\n",
      "Found 0 images in train_iris/ and test_iris/ folders.\n",
      "Iris cropping completed!\n",
      "Dataset split into train_iris/ and test_iris/ folders!\n",
      "Found 4600 images belonging to 2 classes.\n",
      "Found 1746 images belonging to 2 classes.\n",
      "Training samples: 4600\n",
      "Validation samples: 1746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,835,713</span> (7.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,835,713\u001b[0m (7.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,833,729</span> (7.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,833,729\u001b[0m (7.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 740ms/step - accuracy: 0.5877 - loss: 0.7311 - val_accuracy: 0.5641 - val_loss: 0.8065\n",
      "Epoch 2/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 642ms/step - accuracy: 0.6881 - loss: 0.5990 - val_accuracy: 0.5607 - val_loss: 0.7492\n",
      "Epoch 3/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 632ms/step - accuracy: 0.6795 - loss: 0.5932 - val_accuracy: 0.6695 - val_loss: 0.6327\n",
      "Epoch 4/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 613ms/step - accuracy: 0.6944 - loss: 0.5756 - val_accuracy: 0.6340 - val_loss: 0.6602\n",
      "Epoch 5/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 611ms/step - accuracy: 0.7062 - loss: 0.5664 - val_accuracy: 0.6712 - val_loss: 0.5956\n",
      "Epoch 6/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 612ms/step - accuracy: 0.7074 - loss: 0.5599 - val_accuracy: 0.4364 - val_loss: 1.9266\n",
      "Epoch 7/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 610ms/step - accuracy: 0.7217 - loss: 0.5565 - val_accuracy: 0.5447 - val_loss: 0.7252\n",
      "Epoch 8/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.7399 - loss: 0.5154 - val_accuracy: 0.6117 - val_loss: 1.4447\n",
      "Epoch 9/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 634ms/step - accuracy: 0.7590 - loss: 0.5039 - val_accuracy: 0.6323 - val_loss: 0.7727\n",
      "Epoch 10/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 618ms/step - accuracy: 0.7439 - loss: 0.5113 - val_accuracy: 0.6277 - val_loss: 0.8565\n",
      "Epoch 11/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 611ms/step - accuracy: 0.7692 - loss: 0.4813 - val_accuracy: 0.6386 - val_loss: 0.6430\n",
      "Epoch 12/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.7687 - loss: 0.4645 - val_accuracy: 0.7761 - val_loss: 0.4521\n",
      "Epoch 13/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 624ms/step - accuracy: 0.7917 - loss: 0.4523 - val_accuracy: 0.8047 - val_loss: 0.4347\n",
      "Epoch 14/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 610ms/step - accuracy: 0.7908 - loss: 0.4478 - val_accuracy: 0.8162 - val_loss: 0.4047\n",
      "Epoch 15/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 611ms/step - accuracy: 0.7886 - loss: 0.4442 - val_accuracy: 0.6827 - val_loss: 0.6567\n",
      "Epoch 16/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 609ms/step - accuracy: 0.7995 - loss: 0.4286 - val_accuracy: 0.8213 - val_loss: 0.3809\n",
      "Epoch 17/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 610ms/step - accuracy: 0.8019 - loss: 0.4154 - val_accuracy: 0.4691 - val_loss: 2.3664\n",
      "Epoch 18/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 611ms/step - accuracy: 0.8079 - loss: 0.4064 - val_accuracy: 0.4874 - val_loss: 1.6725\n",
      "Epoch 19/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 609ms/step - accuracy: 0.8200 - loss: 0.3811 - val_accuracy: 0.7732 - val_loss: 0.4354\n",
      "Epoch 20/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 628ms/step - accuracy: 0.8290 - loss: 0.3748 - val_accuracy: 0.8253 - val_loss: 0.3570\n",
      "Epoch 21/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 632ms/step - accuracy: 0.8283 - loss: 0.3702 - val_accuracy: 0.6644 - val_loss: 0.6405\n",
      "Epoch 22/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.8336 - loss: 0.3654 - val_accuracy: 0.8448 - val_loss: 0.3360\n",
      "Epoch 23/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.8516 - loss: 0.3326 - val_accuracy: 0.7675 - val_loss: 0.4670\n",
      "Epoch 24/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 655ms/step - accuracy: 0.8492 - loss: 0.3427 - val_accuracy: 0.8906 - val_loss: 0.2481\n",
      "Epoch 25/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 642ms/step - accuracy: 0.8628 - loss: 0.3233 - val_accuracy: 0.9107 - val_loss: 0.2409\n",
      "Epoch 26/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 644ms/step - accuracy: 0.8770 - loss: 0.2945 - val_accuracy: 0.4588 - val_loss: 2.0601\n",
      "Epoch 27/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 644ms/step - accuracy: 0.8737 - loss: 0.2952 - val_accuracy: 0.6111 - val_loss: 0.8493\n",
      "Epoch 28/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 643ms/step - accuracy: 0.8692 - loss: 0.3024 - val_accuracy: 0.8259 - val_loss: 0.3738\n",
      "Epoch 29/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 642ms/step - accuracy: 0.8775 - loss: 0.2950 - val_accuracy: 0.8580 - val_loss: 0.3388\n",
      "Epoch 30/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 643ms/step - accuracy: 0.8725 - loss: 0.2976 - val_accuracy: 0.8757 - val_loss: 0.2745\n",
      "Epoch 31/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 633ms/step - accuracy: 0.8823 - loss: 0.2716 - val_accuracy: 0.9015 - val_loss: 0.2429\n",
      "Epoch 32/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.8858 - loss: 0.2759 - val_accuracy: 0.8494 - val_loss: 0.3385\n",
      "Epoch 33/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 634ms/step - accuracy: 0.8839 - loss: 0.2722 - val_accuracy: 0.8425 - val_loss: 0.3692\n",
      "Epoch 34/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.8837 - loss: 0.2647 - val_accuracy: 0.7211 - val_loss: 0.7302\n",
      "Epoch 35/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 635ms/step - accuracy: 0.8837 - loss: 0.2792 - val_accuracy: 0.7285 - val_loss: 0.9355\n",
      "Epoch 36/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.8843 - loss: 0.2779 - val_accuracy: 0.7938 - val_loss: 0.5155\n",
      "Epoch 37/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.9009 - loss: 0.2280 - val_accuracy: 0.9210 - val_loss: 0.1888\n",
      "Epoch 38/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.8994 - loss: 0.2415 - val_accuracy: 0.8671 - val_loss: 0.2999\n",
      "Epoch 39/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 635ms/step - accuracy: 0.9039 - loss: 0.2463 - val_accuracy: 0.8826 - val_loss: 0.2755\n",
      "Epoch 40/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9100 - loss: 0.2180 - val_accuracy: 0.8814 - val_loss: 0.2767\n",
      "Epoch 41/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9107 - loss: 0.2294 - val_accuracy: 0.8912 - val_loss: 0.2511\n",
      "Epoch 42/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9037 - loss: 0.2341 - val_accuracy: 0.8511 - val_loss: 0.3586\n",
      "Epoch 43/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9133 - loss: 0.2172 - val_accuracy: 0.8373 - val_loss: 0.3889\n",
      "Epoch 44/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9256 - loss: 0.1925 - val_accuracy: 0.9095 - val_loss: 0.2056\n",
      "Epoch 45/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.9116 - loss: 0.2194 - val_accuracy: 0.8963 - val_loss: 0.2331\n",
      "Epoch 46/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 635ms/step - accuracy: 0.9099 - loss: 0.2101 - val_accuracy: 0.8436 - val_loss: 0.3994\n",
      "Epoch 47/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 635ms/step - accuracy: 0.8921 - loss: 0.2564 - val_accuracy: 0.6959 - val_loss: 1.0829\n",
      "Epoch 48/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9142 - loss: 0.2086 - val_accuracy: 0.9570 - val_loss: 0.1079\n",
      "Epoch 49/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9269 - loss: 0.1911 - val_accuracy: 0.9170 - val_loss: 0.1781\n",
      "Epoch 50/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9113 - loss: 0.2109 - val_accuracy: 0.9376 - val_loss: 0.2183\n",
      "Epoch 51/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9185 - loss: 0.2051 - val_accuracy: 0.7314 - val_loss: 0.8717\n",
      "Epoch 52/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9165 - loss: 0.2053 - val_accuracy: 0.9066 - val_loss: 0.2621\n",
      "Epoch 53/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9240 - loss: 0.1912 - val_accuracy: 0.8620 - val_loss: 0.3260\n",
      "Epoch 54/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 637ms/step - accuracy: 0.9146 - loss: 0.1984 - val_accuracy: 0.9542 - val_loss: 0.2212\n",
      "Epoch 55/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9281 - loss: 0.1704 - val_accuracy: 0.8316 - val_loss: 0.6535\n",
      "Epoch 56/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.9185 - loss: 0.1939 - val_accuracy: 0.9284 - val_loss: 0.1964\n",
      "Epoch 57/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9293 - loss: 0.1718 - val_accuracy: 0.7388 - val_loss: 0.8433\n",
      "Epoch 58/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9201 - loss: 0.1964 - val_accuracy: 0.9238 - val_loss: 0.1863\n",
      "Epoch 59/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9224 - loss: 0.1774 - val_accuracy: 0.9496 - val_loss: 0.1344\n",
      "Epoch 60/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.9224 - loss: 0.1733 - val_accuracy: 0.9055 - val_loss: 0.2761\n",
      "Epoch 61/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 640ms/step - accuracy: 0.9190 - loss: 0.1923 - val_accuracy: 0.9507 - val_loss: 0.1398\n",
      "Epoch 62/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 643ms/step - accuracy: 0.9214 - loss: 0.2013 - val_accuracy: 0.9049 - val_loss: 0.2310\n",
      "Epoch 63/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 647ms/step - accuracy: 0.9360 - loss: 0.1751 - val_accuracy: 0.9525 - val_loss: 0.1269\n",
      "Epoch 64/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 618ms/step - accuracy: 0.9292 - loss: 0.1763 - val_accuracy: 0.9548 - val_loss: 0.1561\n",
      "Epoch 65/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 617ms/step - accuracy: 0.9393 - loss: 0.1614 - val_accuracy: 0.9450 - val_loss: 0.1502\n",
      "Epoch 66/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 615ms/step - accuracy: 0.9363 - loss: 0.1614 - val_accuracy: 0.9719 - val_loss: 0.1051\n",
      "Epoch 67/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 610ms/step - accuracy: 0.9404 - loss: 0.1678 - val_accuracy: 0.7612 - val_loss: 0.7043\n",
      "Epoch 68/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 611ms/step - accuracy: 0.9364 - loss: 0.1620 - val_accuracy: 0.9588 - val_loss: 0.1417\n",
      "Epoch 69/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 612ms/step - accuracy: 0.9316 - loss: 0.1670 - val_accuracy: 0.8986 - val_loss: 0.2404\n",
      "Epoch 70/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 634ms/step - accuracy: 0.9346 - loss: 0.1617 - val_accuracy: 0.9553 - val_loss: 0.1190\n",
      "Epoch 71/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 646ms/step - accuracy: 0.9395 - loss: 0.1402 - val_accuracy: 0.8723 - val_loss: 0.3525\n",
      "Epoch 72/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 642ms/step - accuracy: 0.9406 - loss: 0.1577 - val_accuracy: 0.9324 - val_loss: 0.2386\n",
      "Epoch 73/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 644ms/step - accuracy: 0.9228 - loss: 0.1887 - val_accuracy: 0.8545 - val_loss: 0.4634\n",
      "Epoch 74/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 642ms/step - accuracy: 0.9396 - loss: 0.1632 - val_accuracy: 0.9685 - val_loss: 0.0883\n",
      "Epoch 75/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 635ms/step - accuracy: 0.9355 - loss: 0.1594 - val_accuracy: 0.9565 - val_loss: 0.1107\n",
      "Epoch 76/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9474 - loss: 0.1451 - val_accuracy: 0.9410 - val_loss: 0.1872\n",
      "Epoch 77/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9353 - loss: 0.1565 - val_accuracy: 0.8459 - val_loss: 0.4303\n",
      "Epoch 78/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9420 - loss: 0.1463 - val_accuracy: 0.9387 - val_loss: 0.1709\n",
      "Epoch 79/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9431 - loss: 0.1503 - val_accuracy: 0.6575 - val_loss: 1.7786\n",
      "Epoch 80/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9419 - loss: 0.1534 - val_accuracy: 0.8826 - val_loss: 0.4829\n",
      "Epoch 81/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 637ms/step - accuracy: 0.9478 - loss: 0.1353 - val_accuracy: 0.9502 - val_loss: 0.5091\n",
      "Epoch 82/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9413 - loss: 0.1451 - val_accuracy: 0.6426 - val_loss: 1.6488\n",
      "Epoch 83/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9428 - loss: 0.1352 - val_accuracy: 0.9135 - val_loss: 0.3663\n",
      "Epoch 84/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9453 - loss: 0.1381 - val_accuracy: 0.8654 - val_loss: 0.3565\n",
      "Epoch 85/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 640ms/step - accuracy: 0.9408 - loss: 0.1457 - val_accuracy: 0.9467 - val_loss: 0.2470\n",
      "Epoch 86/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 640ms/step - accuracy: 0.9423 - loss: 0.1469 - val_accuracy: 0.9553 - val_loss: 0.1893\n",
      "Epoch 87/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 641ms/step - accuracy: 0.9449 - loss: 0.1339 - val_accuracy: 0.7068 - val_loss: 1.3072\n",
      "Epoch 88/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9458 - loss: 0.1318 - val_accuracy: 0.9570 - val_loss: 0.2837\n",
      "Epoch 89/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 640ms/step - accuracy: 0.9484 - loss: 0.1402 - val_accuracy: 0.9679 - val_loss: 0.1590\n",
      "Epoch 90/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9483 - loss: 0.1319 - val_accuracy: 0.9725 - val_loss: 0.1093\n",
      "Epoch 91/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 644ms/step - accuracy: 0.9427 - loss: 0.1299 - val_accuracy: 0.8706 - val_loss: 0.5809\n",
      "Epoch 92/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9415 - loss: 0.1398 - val_accuracy: 0.8877 - val_loss: 0.3025\n",
      "Epoch 93/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9457 - loss: 0.1434 - val_accuracy: 0.8809 - val_loss: 0.9997\n",
      "Epoch 94/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9543 - loss: 0.1171 - val_accuracy: 0.8568 - val_loss: 0.3912\n",
      "Epoch 95/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9425 - loss: 0.1408 - val_accuracy: 0.9565 - val_loss: 0.1050\n",
      "Epoch 96/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9388 - loss: 0.1505 - val_accuracy: 0.8958 - val_loss: 0.3291\n",
      "Epoch 97/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9506 - loss: 0.1230 - val_accuracy: 0.9055 - val_loss: 0.2331\n",
      "Epoch 98/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9446 - loss: 0.1392 - val_accuracy: 0.9742 - val_loss: 0.1687\n",
      "Epoch 99/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9548 - loss: 0.1251 - val_accuracy: 0.9559 - val_loss: 0.1187\n",
      "Epoch 100/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 641ms/step - accuracy: 0.9479 - loss: 0.1232 - val_accuracy: 0.8505 - val_loss: 0.4495\n",
      "Epoch 101/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 641ms/step - accuracy: 0.9577 - loss: 0.1075 - val_accuracy: 0.9788 - val_loss: 0.0611\n",
      "Epoch 102/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 652ms/step - accuracy: 0.9595 - loss: 0.1099 - val_accuracy: 0.9691 - val_loss: 0.0973\n",
      "Epoch 103/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 646ms/step - accuracy: 0.9610 - loss: 0.1038 - val_accuracy: 0.9439 - val_loss: 0.2230\n",
      "Epoch 104/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 645ms/step - accuracy: 0.9528 - loss: 0.1291 - val_accuracy: 0.9748 - val_loss: 0.1012\n",
      "Epoch 105/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9426 - loss: 0.1304 - val_accuracy: 0.9450 - val_loss: 0.2436\n",
      "Epoch 106/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9540 - loss: 0.1119 - val_accuracy: 0.9742 - val_loss: 0.0756\n",
      "Epoch 107/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 640ms/step - accuracy: 0.9516 - loss: 0.1255 - val_accuracy: 0.9794 - val_loss: 0.0702\n",
      "Epoch 108/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 630ms/step - accuracy: 0.9491 - loss: 0.1288 - val_accuracy: 0.8940 - val_loss: 0.2554\n",
      "Epoch 109/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9580 - loss: 0.1100 - val_accuracy: 0.9782 - val_loss: 0.0696\n",
      "Epoch 110/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9499 - loss: 0.1168 - val_accuracy: 0.8918 - val_loss: 0.3832\n",
      "Epoch 111/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 634ms/step - accuracy: 0.9509 - loss: 0.1120 - val_accuracy: 0.8906 - val_loss: 0.4393\n",
      "Epoch 112/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.9484 - loss: 0.1216 - val_accuracy: 0.9674 - val_loss: 0.1037\n",
      "Epoch 113/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.9605 - loss: 0.1041 - val_accuracy: 0.9811 - val_loss: 0.0451\n",
      "Epoch 114/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 636ms/step - accuracy: 0.9633 - loss: 0.1037 - val_accuracy: 0.9800 - val_loss: 0.5361\n",
      "Epoch 115/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 635ms/step - accuracy: 0.9566 - loss: 0.1199 - val_accuracy: 0.9691 - val_loss: 1.0206\n",
      "Epoch 116/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 642ms/step - accuracy: 0.9718 - loss: 0.0802 - val_accuracy: 0.9336 - val_loss: 0.4780\n",
      "Epoch 117/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 641ms/step - accuracy: 0.9554 - loss: 0.1238 - val_accuracy: 0.9805 - val_loss: 0.2834\n",
      "Epoch 118/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 642ms/step - accuracy: 0.9566 - loss: 0.1250 - val_accuracy: 0.9777 - val_loss: 0.1478\n",
      "Epoch 119/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 641ms/step - accuracy: 0.9536 - loss: 0.1154 - val_accuracy: 0.9324 - val_loss: 0.1961\n",
      "Epoch 120/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9703 - loss: 0.0854 - val_accuracy: 0.8786 - val_loss: 0.3777\n",
      "Epoch 121/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 633ms/step - accuracy: 0.9568 - loss: 0.1119 - val_accuracy: 0.9656 - val_loss: 0.1082\n",
      "Epoch 122/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9528 - loss: 0.1145 - val_accuracy: 0.9765 - val_loss: 0.2091\n",
      "Epoch 123/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 641ms/step - accuracy: 0.9638 - loss: 0.0919 - val_accuracy: 0.8196 - val_loss: 0.7725\n",
      "Epoch 124/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9643 - loss: 0.0892 - val_accuracy: 0.9742 - val_loss: 0.0726\n",
      "Epoch 125/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 633ms/step - accuracy: 0.9603 - loss: 0.0981 - val_accuracy: 0.9490 - val_loss: 0.1477\n",
      "Epoch 126/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9620 - loss: 0.1037 - val_accuracy: 0.9794 - val_loss: 0.0644\n",
      "Epoch 127/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9498 - loss: 0.1198 - val_accuracy: 0.9026 - val_loss: 0.3348\n",
      "Epoch 128/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9602 - loss: 0.1038 - val_accuracy: 0.8900 - val_loss: 0.3065\n",
      "Epoch 129/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 641ms/step - accuracy: 0.9653 - loss: 0.0948 - val_accuracy: 0.9502 - val_loss: 0.1388\n",
      "Epoch 130/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 641ms/step - accuracy: 0.9647 - loss: 0.0952 - val_accuracy: 0.9519 - val_loss: 0.1948\n",
      "Epoch 131/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 638ms/step - accuracy: 0.9566 - loss: 0.1118 - val_accuracy: 0.9490 - val_loss: 0.1388\n",
      "Epoch 132/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9586 - loss: 0.1061 - val_accuracy: 0.9897 - val_loss: 0.0296\n",
      "Epoch 133/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9611 - loss: 0.0959 - val_accuracy: 0.9685 - val_loss: 0.1019\n",
      "Epoch 134/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 640ms/step - accuracy: 0.9639 - loss: 0.0929 - val_accuracy: 0.9857 - val_loss: 0.0469\n",
      "Epoch 135/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 640ms/step - accuracy: 0.9612 - loss: 0.0978 - val_accuracy: 0.8293 - val_loss: 0.5767\n",
      "Epoch 136/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9640 - loss: 0.0945 - val_accuracy: 0.9422 - val_loss: 0.2356\n",
      "Epoch 137/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9668 - loss: 0.0886 - val_accuracy: 0.9129 - val_loss: 0.2466\n",
      "Epoch 138/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 637ms/step - accuracy: 0.9662 - loss: 0.0834 - val_accuracy: 0.9536 - val_loss: 0.1610\n",
      "Epoch 139/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 640ms/step - accuracy: 0.9634 - loss: 0.0973 - val_accuracy: 0.8717 - val_loss: 0.3931\n",
      "Epoch 140/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 640ms/step - accuracy: 0.9628 - loss: 0.0922 - val_accuracy: 0.9679 - val_loss: 0.1036\n",
      "Epoch 141/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 640ms/step - accuracy: 0.9692 - loss: 0.0771 - val_accuracy: 0.8889 - val_loss: 0.3756\n",
      "Epoch 142/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 642ms/step - accuracy: 0.9650 - loss: 0.0866 - val_accuracy: 0.9811 - val_loss: 0.0613\n",
      "Epoch 143/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9707 - loss: 0.0748 - val_accuracy: 0.9559 - val_loss: 0.1266\n",
      "Epoch 144/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 640ms/step - accuracy: 0.9609 - loss: 0.1065 - val_accuracy: 0.9891 - val_loss: 0.0349\n",
      "Epoch 145/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9700 - loss: 0.0730 - val_accuracy: 0.8162 - val_loss: 0.8301\n",
      "Epoch 146/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 637ms/step - accuracy: 0.9632 - loss: 0.0997 - val_accuracy: 0.9656 - val_loss: 0.0912\n",
      "Epoch 147/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 630ms/step - accuracy: 0.9693 - loss: 0.0842 - val_accuracy: 0.7440 - val_loss: 1.7905\n",
      "Epoch 148/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 639ms/step - accuracy: 0.9592 - loss: 0.0948 - val_accuracy: 0.9502 - val_loss: 0.1387\n",
      "Epoch 149/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 646ms/step - accuracy: 0.9639 - loss: 0.0922 - val_accuracy: 0.9834 - val_loss: 0.0575\n",
      "Epoch 150/150\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 645ms/step - accuracy: 0.9614 - loss: 0.0871 - val_accuracy: 0.9782 - val_loss: 0.0518\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - accuracy: 0.9606 - loss: 0.0849\n",
      "\n",
      "Test accuracy: 0.9782\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.99      0.97      0.98       984\n",
      "           M       0.96      0.99      0.98       762\n",
      "\n",
      "    accuracy                           0.98      1746\n",
      "   macro avg       0.98      0.98      0.98      1746\n",
      "weighted avg       0.98      0.98      0.98      1746\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[952  32]\n",
      " [  6 756]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from roboflow import Roboflow\n",
    "import supervision as sv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from inference_sdk import InferenceHTTPClient, InferenceConfiguration\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Libraries installed and imported successfully!\")\n",
    "\n",
    "\n",
    "#  SETUP LOCAL DATASET AND FOLDER\n",
    "\n",
    "\n",
    "# Define the path to the local dataset\n",
    "dataset_folder = r\"C:\\Users\\MaadGroup\\Desktop\\project\\Dataset\\cropped_iris\" # مسیر پوشه اصلی\n",
    "train_folder = os.path.join(dataset_folder, \"train_iris\")\n",
    "test_folder = os.path.join(dataset_folder, \"test_iris\")\n",
    "\n",
    "image_paths = glob.glob(os.path.join(train_folder, \"**\", \"*.jpg\"), recursive=True) + \\\n",
    "              glob.glob(os.path.join(test_folder, \"**\", \"*.jpg\"), recursive=True)\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in train_iris/ and test_iris/ folders.\")\n",
    "\n",
    "# Set output folder for cropped images\n",
    "cropped_output_folder = \"cropped_iris\"\n",
    "os.makedirs(cropped_output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# PROCESS CROPPED IMAGES AND EXTRACT GENDER FROM FILENAMES\n",
    "\n",
    "\n",
    "# Function to extract gender from filename\n",
    "def get_gender_from_filename(filename):\n",
    "    # Assuming the first character of the filename is the gender label (F or M)\n",
    "    gender_label = filename.upper()[0]  # Get the first character\n",
    "    if gender_label in [\"F\", \"M\"]:\n",
    "        return gender_label\n",
    "    else:\n",
    "        return \"U\"  # Unknown\n",
    "\n",
    "# Start processing the images\n",
    "for idx, img_path in enumerate(image_paths):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        print(f\"Cannot read {img_path}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Extract gender label from the filename\n",
    "    base_name = os.path.basename(img_path)\n",
    "    gender_label = get_gender_from_filename(base_name)\n",
    "\n",
    "    # Save cropped iris with gender prefix\n",
    "    file_name = f\"{gender_label}_{os.path.splitext(base_name)[0]}_crop.jpg\"\n",
    "    out_path = os.path.join(cropped_output_folder, file_name)\n",
    "    cv2.imwrite(out_path, image)\n",
    "\n",
    "print(\"Iris cropping completed!\")\n",
    "\n",
    "\n",
    "#  PREPARE THE FINAL DATASET (CROPPED IRIS IMAGES) FOR CNN TRAINING\n",
    "\n",
    "\n",
    "cropped_image_paths = glob.glob(os.path.join(cropped_output_folder, \"*.jpg\"))\n",
    "\n",
    "# We will create two folders: train_iris/ (80% of images) and test_iris/ (20%).\n",
    "train_folder = \"train_iris\"\n",
    "test_folder = \"test_iris\"\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Create subdirectories: F and M\n",
    "for label in [\"F\", \"M\"]:\n",
    "    os.makedirs(os.path.join(train_folder, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_folder, label), exist_ok=True)\n",
    "\n",
    "# Separate images by label\n",
    "f_images = [p for p in cropped_image_paths if os.path.basename(p).upper().startswith(\"F\")]\n",
    "m_images = [p for p in cropped_image_paths if os.path.basename(p).upper().startswith(\"M\")]\n",
    "\n",
    "# Split each label set into train/test\n",
    "f_train, f_test = train_test_split(f_images, test_size=0.2, random_state=42)\n",
    "m_train, m_test = train_test_split(m_images, test_size=0.2, random_state=42)\n",
    "\n",
    "def copy_files(file_list, target_folder):\n",
    "    for path in file_list:\n",
    "        filename = os.path.basename(path)\n",
    "        dest = os.path.join(target_folder, filename)\n",
    "        shutil.copy(path, dest)\n",
    "\n",
    "# Copy F images\n",
    "copy_files(f_train, os.path.join(train_folder, \"F\"))\n",
    "copy_files(f_test, os.path.join(test_folder, \"F\"))\n",
    "# Copy M images\n",
    "copy_files(m_train, os.path.join(train_folder, \"M\"))\n",
    "copy_files(m_test, os.path.join(test_folder, \"M\"))\n",
    "\n",
    "print(\"Dataset split into train_iris/ and test_iris/ folders!\")\n",
    "\n",
    "\n",
    "#  BUILD A CNN MODEL IN KERAS FOR GENDER CLASSIFICATION\n",
    "\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "# Data augmentation for training set\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_folder,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_folder,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {test_generator.samples}\")\n",
    "\n",
    "# Build an improved CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # Additional convolutional layers with more filters\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "#  TRAIN THE MODEL AND VALIDATE IT ON THE TEST SET\n",
    "\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Let Keras automatically determine steps_per_epoch\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    validation_data=test_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "#  EVALUATE THE MODEL AND DISPLAY METRICS\n",
    "\n",
    "\n",
    "# Reset generators before evaluation\n",
    "train_generator.reset()\n",
    "test_generator.reset()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Generate predictions\n",
    "preds = model.predict(test_generator)\n",
    "pred_classes = (preds > 0.5).astype(int)\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_classes, pred_classes, target_names=class_labels))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(true_classes, pred_classes)\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578397b-0916-4eab-8af6-fbf24e44a8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
